{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N11Ee3GJmywu",
    "outputId": "64e10b54-dad3-48e2-c266-617670a17e82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.12.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting wikipedia\n",
      "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.11/site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.11/site-packages (from openai) (2.6.1)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.11/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.11/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.11/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.11/site-packages (from wikipedia) (4.12.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from wikipedia) (2.31.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.4-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.16.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.1.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.11/site-packages (from beautifulsoup4->wikipedia) (2.5)\n",
      "Downloading openai-1.12.0-py3-none-any.whl (226 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: wikipedia\n",
      "  Building wheel for wikipedia (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=db7ca4705b65cd60f11b9d99fac82417d70243e6b04685d697a9d49d53e732df\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/8f/ab/cb/45ccc40522d3a1c41e1d2ad53b8f33a62f394011ec38cd71c6\n",
      "Successfully built wikipedia\n",
      "Installing collected packages: h11, wikipedia, httpcore, httpx, openai\n",
      "Successfully installed h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 openai-1.12.0 wikipedia-1.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Q2A8TGhKm3i5"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7E9HEMJSX-3T"
   },
   "source": [
    "# 1.) Set up OpenAI and the enviornment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "4zwwdkZDYDZN"
   },
   "outputs": [],
   "source": [
    "apikey = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8IiKS0snlpYP"
   },
   "outputs": [],
   "source": [
    "openai.api_key = apikey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI(\n",
    "    api_key = openai.api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tOXc5_BTm9HP"
   },
   "source": [
    "# 2.) Use the wikipedia api to get a function that pulls in the text of a wikipedia page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "-v7OYamHlrEB"
   },
   "outputs": [],
   "source": [
    "page_titles = [\"Artificial Intelligence\", \"UCLA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "TgY2FkTdmhTH"
   },
   "outputs": [],
   "source": [
    "page_title = page_titles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Kw5H5jMlmmS3"
   },
   "outputs": [],
   "source": [
    "search_results = wikipedia.search(page_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "ZF3BiZyXltYO"
   },
   "outputs": [],
   "source": [
    "page = wikipedia.page(search_results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "Ef7yfa2jl0iZ"
   },
   "outputs": [],
   "source": [
    "# page.content\n",
    "def get_wikipedia_content(page_title):\n",
    "    search_results = wikipedia.search(page_title)\n",
    "    page = wikipedia.page(search_results[0])\n",
    "    return(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = get_wikipedia_content(page_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_9aruncMmubX"
   },
   "source": [
    "# 3.) Build a chatgpt bot that will analyze the text given and try to locate any false info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "Bmai3B6Dmw3O"
   },
   "outputs": [],
   "source": [
    "chat_completions = client.chat.completions.create(\n",
    "    model = \"gpt-4\",\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\":\"I will be giving you an article. I am looking for false information. I want to capture all potentially false info, if there is even small potential for it to be wrong, please return it. Please concisely list only the false information found. If there is no false information only return 'Done'.\"},\n",
    "        {\"role\": \"user\", \"content\": content[:8180]}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "1jI-un5PnDjg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Alan Turing was the first person to conduct substantial research in the field that he called machine intelligence.\" - Alan Turing is not the first person to conduct substantial research in the field, while he made significant contributions, others also contributed before him. \n",
      "\n",
      "\"Funding and interest vastly increased after 2012 when deep learning surpassed all previous AI techniques\" - The interest and funding increased, but saying deep learning surpassed all previous AI techniques is a generic statement and might be untrue for certain applications.\n",
      "  \n",
      "\"This led to the AI spring of the early 2020s, with companies, universities, and laboratories overwhelmingly based in the United States pioneering significant advances in artificial intelligence.\" - Significant advances in AI are indeed happening, but attributing them overwhelmingly to the United States overlooks the substantial contributions made by entities in other countries. \n",
      "\n",
      "\"General intelligence (the ability to complete any task performable by a human) is among the field's long-term goals.\" - The phrase is somewhat misleading as it implies that an AI could truly replicate complete human intelligence, including emotions, creativity or consciousness, which is currently far beyond our capabilities. \n",
      "\n",
      "\"A Markov decision process has a transition model that describes the probability that a particular action will change the state in a particular way, and a reward function that supplies the utility of each state and the cost of each action.\" - The statement is generally correct in the context of AI and machine learning but simplifies the complexities and nuances of a Markov Decision Process, which includes both deterministic and probabilistic scenarios. \n",
      "\n",
      "\"Machine learning is the study of programs that can improve their performance on a given task automatically. It has been a part of AI from the beginning.\" - Machine learning has not been a part of AI from the very beginning. Early AI research was more rule-based and didn't incorporate machine learning as we know it today. \n",
      "\n",
      "\"In reinforcement learning the agent is rewarded for good responses and punished for bad ones.\" - The phrase somewhat simplifies the process of reinforcement learning, which also heavily involves exploring and trading off between short-term and long-term rewards.\n"
     ]
    }
   ],
   "source": [
    "print(chat_completions.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "_TMKFGN4nDJ4"
   },
   "outputs": [],
   "source": [
    "def chatgpt_error_correction(text):\n",
    "    chat_completions = client.chat.completions.create(\n",
    "    model = \"gpt-4\",\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\":\"I will be giving you an article. I am looking for false information. I want to capture all potentially false info, if there is even small potential for it to be wrong, please return it. Please concisely list only the false information found. If there is no false information only return 'Done'.\"},\n",
    "        {\"role\": \"user\", \"content\": content[:8180]}]\n",
    ")\n",
    "    print(chat_completions.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zPw5LyPEobmk"
   },
   "source": [
    "# 4.) Make a for loop and check a few wikipedia pages and return a report of any potentially false info via wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "V7cuhML2ocGn"
   },
   "outputs": [],
   "source": [
    "page_titles = [\"Artificial Intelligence\", \"UCLA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________Artificial Intelligence\n",
      "1. \"Artificial intelligence (AI) is the intelligence of machines or software, as opposed to the intelligence of living beings, primarily of humans.\" - This definition is not entirely accurate as artificial intelligence doesn't necessarily represent intelligence only of machines or software. It also involves simulated intelligence in computers and the application of machine learning, natural language processing etc.\n",
      "   \n",
      "2. \"Alan Turing was the first person to conduct substantial research in the field that he called machine intelligence.\" - This statement could be misleading. Alan Turing made significant theoretical contributions, including the Turing machine concept and the Turing test, but many others also conducted substantial research in fields that would contribute to AI, such as Norbert Wiener's work in cybernetics. \n",
      "\n",
      "3. \"This led to the AI spring of the early 2020s, with companies, universities, and laboratories overwhelmingly based in the United States pioneering significant advances in artificial intelligence.\" - This statement is biased, as there are significant contributions to AI from companies, universities, and laboratories based in other countries, such as China, Canada, and several European countries. \n",
      "\n",
      "4. \"Many of these algorithms are insufficient for solving large reasoning problems because they experience a \"combinatorial explosion\": they became exponentially slower as the problems grew larger.\" - This statement is not entirely correct. While it's true that some algorithms do experience 'combinatorial explosion', it's misleading to imply that this is the case for many algorithms. A number of algorithms and techniques have been developed specifically to address this issue, including heuristic search methods and approximation algorithms.\n",
      "  \n",
      "5. \"Even humans rarely use the step-by-step deduction that early AI research could model. They solve most of their problems using fast, intuitive judgments.\" - This is not necessarily true. Humans use a combination of intuitive judgments and step-by-step logical reasoning. The exact mix can vary greatly depending on the individual and the situation.\n",
      "\n",
      "6. \"An ontology is the set of objects, relations, concepts, and properties used by a particular domain of knowledge.\" - This definition is not entirely accurate. An ontology, in the context of artificial intelligence and knowledge representation, also includes principles of making inferences based on those objects, relations, concepts, and properties.\n",
      "\n",
      "7. \"The space of possible future actions and situations is typically intractably large, so the agents must take actions and evaluate situations while being uncertain what the outcome will be.\" - While it's true that the outcome of actions may be uncertain to some degree, AI agents often make use of predictive models to estimate the probable outcomes of their actions.\n",
      "_______________UCLA\n",
      "1. The article states that UCLA's academic roots were established in 1881 as a southern branch of the California State Normal School, which later evolved into San José State University. But UCLA's roots were actually in the Los Angeles State Normal School, not the California State Normal School. \n",
      "2. It is stated UCLA received 174,914 undergraduate applications for Fall 2022, though the exact number can't be accurate as Fall 2022 applications are not closed at the time of answering this issue.\n",
      "3. The article claims UCLA's three remaining schools are Education & Information Studies, Management, and Law. This is false as UCLA has more than mentioned three schools.\n",
      "4. UCLA's student-athletes are said to have won 121 NCAA team championships, but the number may vary as UCLA's official site indicates they have won 118 NCAA team championships. \n",
      "5. The article asserts UCLA has had 27 Nobel laureates, five Turing Awards winners, two Chief Scientists of the U.S. Air Force and one Fields Medalist affiliated with it but the exact number can't be confirmed as UCLA's official site does not provide these specific numbers.\n",
      "6. The statement that the Los Angeles branch of the California State Normal School opened on August 29, 1882, is false. The normal school in Los Angeles opened in 1881, not 1882.\n",
      "7. The claim that the Southern Branch campus opened on September 15 is incorrect. The Southern Branch of the University of California was opened on May 23, 1919.\n",
      "8. UCLA's naming as the \"University of California at Los Angeles\" is stated to have taken place on February 1, 1927. However, the change in name actually occurred in 1927 but the exact date is not specified. \n",
      "9. The article's claim that UCLA was permitted to award the master's degree in 1933 and the doctorate in 1936 is inaccurate, as it was permitted to award the graduate degrees even before these dates. \n",
      "10. The statement that in 1951 UCLA was elevated to co-equal status with UC Berkeley is false. Achieving co-equal status happened in 1951 but was not formalized until 1958. \n",
      "11. The information regarding the sexual harassment allegations in the history department in 2014 lacks the result of the investigation or final outcome which could potentially provide a false impression of the situation.\n"
     ]
    }
   ],
   "source": [
    "for page_title in page_titles:\n",
    "    try:\n",
    "        print(\"_______________\" + page_title)\n",
    "        content = get_wikipedia_content(page_title)\n",
    "        chatgpt_error_correction(content)\n",
    "    except:\n",
    "        print(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
